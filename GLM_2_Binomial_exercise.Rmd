---
title: "Exercise"
# author: TCornulier
output:
  html_document: 
    toc: no
    code_folding: hide
editor_options:
  chunk_output_type: console
---


```{r setup, echo=FALSE, purl = FALSE}
knitr::opts_chunk$set(echo=TRUE, message = FALSE, warning = FALSE, eval = FALSE, cache = FALSE)

SOLUTIONS<- FALSE
```

\  

# Binomial (Bernoulli) GLM - dolphin behavioural plasticity

\  

1\. The data for this exercise were collected by the Cromarty Lighthouse team, using underwater sound recorders (CPOD) to continuously monitor the pattern of presence and foraging behaviour of bottlenose dolphins at Sutors, in the Moray Firth, between 2010 and 2016. Additional background for this study is provided at the end of the exercise, in case of interest. 

* Variables:
  + `X` index of the observations
  + `presence`: 0 for absence, 1 for presence in 1h time slot. Note that "absence" refers to the absence of a detection, not to the absence of dolphins. We can ignore this in the analysis, but we should keep it in mind when interpreting the results.
  + `year`
  + `julianday`: day of the year
  + `tideangle_deg`: continuous tidal state, from high to ebb, low and flood
  + `mh`: hour of the day (integer)
  + `mon`: month (integer)
  + `Time6`: Bin time of day into 6 4h periods: MNight (2200-0200); AM1 (0200-0600); AM2 (06:00-10:00); MDay (10:00-14:00); PM1 (14:00-18:00); PM2 (18:00-22:00)
  + `Tide4`: Bin tide angle into 4 quadrants with tide peaks (high, descending, low, rising) in middle of respective bin

* It has been suggested that the patterns of use of coastal foraging sites by this dolphin population is quite variable over time. The goal of this exercise is to describe variation in dolphin probability of presence in relation to factors like tidal state, time of day and season.

* As in previous exercises, either create a new R script (perhaps call it GLM_PresAbs) or continue with your previous R script in your RStudio Project. Again, make sure you include any metadata you feel is appropriate (title, description of task, date of creation etc) and  don't forget to comment out your metadata with a `#` at the beginning of the line. 

\  

2\. Import the data file 'dolphin.csv' into R (a "small" 5000 records-long subset of the original data set) by running the following chunk of code (please unfold and copy/paste - adjust the path as required).

\  

```{r Q2, eval=TRUE, echo=TRUE, results=TRUE, collapse=FALSE}

dat<- read.csv("./data/dolphin.csv", stringsAsFactors= T)

dat$Time6<- factor(dat$Time6, levels= c("MNight", "AM1", "AM2", "MDay", "PM1", "PM2"))
# reordering chronologically

str(dat)
```
 
\  

3\. Take a look at the structure of this dataframe, and do an initial data exploration. 

* Some things you could focus on are:
  + look at any correlation/data imbalance (different sample sizes between portions of a predictor variable) for all predictors, or useful combinations of predictors (for example `year` and `month`, `Tide4` and time of day `mh`)
  + look for factors affecting the probability of presence of dolphins (proportion of time present). Which ones are continuous or categorical? Which ones would your intuition guide you to use for modelling?

* Notes:
  + Presence/absence data (Bernoulli) are more difficult than most to explore.
  + One approach for data imbalance is to count observations per categories of interest.
  + `table()` is a useful way to count the number of observations per category or combinations of categories, e.g. `ObsPerMonthYear<- table(dat$year, dat$mon)`
  + `plot(ObsPerMonthYear)` returns a "mosaic plot" where the area of each rectangle is proportional to the count.
  + For factors affecting the proportion of time present, you could calculate mean presence per category, which is the proportion of time present: `bla<- tapply(dat$presence, list(dat$GroupOfInterest), mean)` and plot this using `plot(bla, type= "b", ylim= c(0, 1), xlab= "GroupOfInterest", ylab= "presence")`
  + In more than one dimension, `tmp<- tapply(dat$presence, list(dat$Group1, dat$Group2), mean)` calculates the proportion of time present for each combination of Group1 and Group2, and `matplot(tmp, type= "l", ylim= c(0, 1), xlab= "Group1", ylab= "presence", lty= 1)` plots the proportion of time present against Group1, with a separate line per Group2 categories.

\  

```{r Q3, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE, fig.show= ifelse(SOLUTIONS, "asis", "hide")}
# count observations per year/month combination and represent as mosaicplot
plot(table(dat$year, dat$mon))
# CPOD failure in Feb-April 2012 and Dec 2012-March 2013

plot(table(dat$mh))
# fairly even representation of hours
# (that's on the random sample; Almost perfectly balanced on the full dataset)
# we should have no problem using 'mh' as a predictor in the model

plot(table(dat$Tide4, dat$mh))
# even representation of tides
# time of day and tidal phase not independent (but not a linear correlation)
# This is balanced enough that we should have no problem using 'mh', Tide4
# or their interaction as predictors in the model.

#### Now, investigating variation in probability of encounter:
#
# presence in relation to time of day
mean.per.mh<- tapply(dat$presence, list(dat$mh), mean)
plot(mean.per.mh, type= "l", ylim= c(0, 1),
		 xlab= "time of day", ylab= "proportion of hours present")
# Probability slightly lower in the middle of the day

# are there seasonal patterns?
mean.per.mon<- tapply(dat$presence, list(dat$mon), mean)
plot(mean.per.mon, type= "l",
				ylim= c(0, 1), xlab= "month", ylab= "proportion of hours present")
# Probability of presence lower in Jan-March?

# presence in relation to tide
mean.per.Tide4<- tapply(dat$presence, list(dat$Tide4), mean)
plot(mean.per.Tide4, type= "b", ylim= c(0, 1),
     xlab= "tidal phase",
		 ylab= "proportion of hours present")
# No obvious effect of tidal phase on average?


# If interested, we could also ask more complex questions, involving interactions between predictors, for example:

# are seasonal patterns similar between years?
# let's calculate the mean per month for each year,
# and plot the seasonal pattern lines for individual years together
mean.per.month.year<- tapply(dat$presence, list(dat$mon, dat$year), mean)
# (month in rows, years in columns)

# matplot draws one line per column (year)
matplot(mean.per.month.year, type= "l",
				ylim= c(0, 1), xlab= "month", ylab= "proportion of hours present")

legend(x= "topleft", legend= colnames(mean.per.month.year),
       bty= "n", # no bounding box for the legend
       col= 1:ncol(mean.per.month.year),
       lty= 1:ncol(mean.per.month.year),
       title= "Year")

# This suggests broadly similar seasonal patterns of variation across years,
# with very low probability of presence from Jan to March

# We could also explore if the effect of some predictors changes between seasons:
# Seasonal variation in diel pattern
mean.per.month.Time6<- tapply(dat$presence, list(dat$mon, dat$Time6), mean)
matplot(mean.per.month.Time6, type= "l", 
        ylim= c(0, 1), 
				xlab= "month", ylab= "proportion of hours present", lty= 1)

legend(x= "topleft", legend= colnames(mean.per.month.Time6),
       bty= "n", # no bounding box for the legend
       col= 1:ncol(mean.per.month.Time6),
       lty= 1:ncol(mean.per.month.Time6),
       title= "Time6")

# stronger diel pattern in later part of the year:
# the lines for different parts of the day diverge quite
# strongly from Sept to Jan.

# are seasonal patterns similar between Tide4 levels?
# let's calculate the mean per month for each tidal stage,
mean.per.month.Tide4<- tapply(dat$presence, list(dat$mon, dat$Tide4), mean)
matplot(mean.per.month.Tide4, type= "l",
       ylim= c(0, 1),
			 xlab= "month", ylab= "proportion of hours present", lty= 1)

legend(x= "topleft", legend= colnames(mean.per.month.Tide4),
       bty= "n", # no bounding box for the legend
       col= 1:ncol(mean.per.month.Tide4),
       lty= 1:ncol(mean.per.month.Tide4),
       title= "Tide4")

# no dramatic change in pattern of tide use across seasons, 
# as all the lines follow a broadly similar trajectory:
# the probability of sighting is mostly affected by season.
# There are variations among tide levels but more subtle.
# Would such an interaction turn out to be significant in a model?

```

\  

4\. We will start with a toy model, to get you started thinking about the problem. You will need to specify a Binomial (Bernoulli) GLM (using `glm()` and the appropriate `family` argument). Let's include the main effects of numerical time of day, tide angle and day of the year as predictors: `tideangle_deg + mh + julianday`.

\  

```{r Q4, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE}
PA1<- glm(presence ~ tideangle_deg + mh + julianday, family= binomial, data= dat)
```

\  

5\. Obtain summaries of the model output using the `summary()` function. Make sure you understand the mathematical and biological interpretation of the model, by writing down the complete model on paper (with distribution and link function). What biological hypothesis does each term imply, qualitatively? Is this model biologically sensible? 

\  

```{r Q5, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE}
summary(PA1)

# Model description:
# presence ~ Bernoulli(p)  or presence ~ Binomial(N= 1, p)
# log(p / (1-p)) = 
#       -1.40*(Intercept) + -0.00044*tideangle_deg + 0.0012*mh 
#       + 0.0022*julianday 

# "(Intercept)" general intercept
# "tideangle_deg" main effect of tide angle, assumes a linear decrease 
# (negative coefficient) of probability of presence from high to flood stages
# "mh" main effect of time of day, assumes a linear  increase 
# of probability of presence from the first hour of the day to the last
# "julianday" main effect of day of year, assumes a linear increase 
# of probability of presence from 1st Jan to 31st Dec

# Note that interpretations above are linear effects on the link scale,
# but sigmoidal on the probability scale, thanks to the logit link

```

\  

6\. Let's now validate the model, using deviance residuals. The easiest tool is the `binnedplot()` in the `arm` package, if you can. If you cannot install the arm package and access its binnedplot, use the "DIY" alternative code chunk further down.

\  

```{r Q6a, eval=TRUE, echo=TRUE, results=SOLUTIONS, collapse=TRUE, fig.show= ifelse(SOLUTIONS, "asis", "hide"), fig.height=8, fig.width=8}
library(car)
vif(PA1)
# No concern.

par(mfrow= c(2, 2))
plot(PA1, col= dat$presence + 1) # red is presence, black is absence
# Not very useful or pretty statistical art. Not worth framing.

# plot against predictors:
res1.p<- resid(PA1, type= "pearson")

par(mfrow= c(2, 2))
plot(res1.p ~ dat$tideangle_deg, col= dat$presence + 1)

plot(res1.p ~ dat$mh, col= dat$presence + 1)

plot(res1.p ~ dat$julianday, col= dat$presence + 1)

# Can't see anything useful.

# Use arm if you can:
library(arm)
par(mfrow= c(2, 2))
binnedplot(x= dat$tideangle_deg, y= res1.p, xlab= "Tide angle", nclass= 100)
binnedplot(x= dat$mh, y= res1.p, xlab= "hour")
binnedplot(x= dat$julianday, y= res1.p, xlab= "Day of the year", nclass= 100)
```

\  

```{r Q6b, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE}
# clearly some unwanted patterns, especially in mh and julianday
# but possibly in tide angle, too
# all pointing at non-linear effects of the predictors on the response

# This is rather expected indeed: for example, it wouldn't make biological 
# sense for the probability of presence to go up from 00:01 am to 23:59 pm,
# and then drop suddently after midnight to start low again at
# 00:01 the next day. Dolphins don't evaporate at midnight.
# The same reasoning applies for the other cycles, tide and season

```

\  

In case needed, a home-made alternative to the `binnedplot` function:

\  

```{r Q6c, eval=TRUE, echo=TRUE, results=SOLUTIONS, collapse=TRUE, fig.show= ifelse(SOLUTIONS, "asis", "hide"), fig.height=8, fig.width=8}
par(mfrow= c(2, 2))
# plot the residuals against tideangle_deg
plot(res1.p ~ dat$tideangle_deg, col= dat$presence + 1)
# get the mean of the residuals for each 1 degree bin of tideangle_deg
tide.means<- tapply(res1.p, list(dat$tideangle_deg), mean)
# convert ordered bin labels into numbers (1 to 360)
tide.vals<- as.numeric(names(tide.means))
# plot residual means against bin number
lines(tide.means ~ tide.vals, col= 3)
# add horizontal line at y= 0 for reference
abline(h= 0, lty= 3, col= grey(0.5))

# same idea for hour of the day:
plot(res1.p ~ dat$mh, col= dat$presence + 1)
hour.means<- tapply(res1.p, list(dat$mh), mean)
lines(hour.means ~ as.numeric(names(hour.means)), col= 3)
abline(h= 0, lty= 3, col= grey(0.5))

# same for julianday:
plot(res1.p ~ dat$julianday, col= dat$presence + 1)
day.means<- tapply(res1.p, list(dat$julianday), mean)
lines(day.means ~ as.numeric(names(day.means)), col= 3)
abline(h= 0, lty= 3, col= grey(0.5))

# Same story.
```

\  

7\. Are you happy with the diagnostic plots? Is there something you could do to improve the model while addressing the initial question(s)? Spend some time looking at the available predictors, and working out what your model should look like, before reading the hints in the code chunk below. If you have relevant biological information, or insight from your data exploration that suggests a better approach than what is indicated below, feel free to try it for comparison.

\  

```{r Q7a, eval=TRUE, echo=TRUE, results=SOLUTIONS, collapse=TRUE}
# Please take the time to think before unfolding the next code chunk

```

\  

```{r Q7b, eval=TRUE, echo=TRUE, results=SOLUTIONS, collapse=TRUE}
# The issue is that the effects of these predictors are not linear
# on the logit (link) scale.

# There are several ways the non-linearity could be addressed. 
# one of the most straightforward with glm() is to discretize
# continuous predictors into bins and to treat them as factors.
# In this way, a mean is estimated per category of the variable,
# and no assumption is made about the shape of the relationship.

# Each of the predictors we started with already has one or more 
# categorical counterpart in the data set.
# I suggest you try fTide4 + fMonth + Time6, with fTide4 and
# fMonth being the factor version of Tide4 and mon (both need creating).

```

\  

8\. Fit the new version of the model. Are all the terms significant? If not, simplify the model. Remember to choose the correct ANOVA method (sequential or not), and the appropriate test. What is the proportion of deviance explained?

\  

```{r Q8, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE}
# convert numerically coded categorical variables into factors:
dat$fTide4<- factor(dat$Tide4)
dat$fMonth<- factor(dat$mon)

PA10<- glm(presence ~ fTide4 + fMonth + Time6, family= binomial, data= dat)

drop1(PA10, test= "Chisq")
# all terms significant; nothing to drop

# out of interest, the total proportion of deviance explained is 
(PA10$null.deviance - PA10$deviance) / PA10$null.deviance # 7%
```

\  

9\. Do the model validation for the minimal adequate model. Is everything looking good?

\  

```{r Q9, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE, fig.show= ifelse(SOLUTIONS, "asis", "hide"), fig.height=8, fig.width=8}
# plot against predictors:
res10.p<- resid(PA10, type= "pearson")

boxplot(res10.p ~ dat$fMonth, xlab= "month")
# boxplot is not a great way to diagnose issues, due to the odd distribution of residuals in the logistic regression

library(arm)
par(mfrow= c(2, 2))
binnedplot(x= dat$tideangle_deg, y=  res10.p, xlab= "Tide angle", nclass= 100)
# okay
binnedplot(x= dat$mh, y=  res10.p, xlab= "hour")
# okay
binnedplot(x= dat$julianday, y=  res10.p, xlab= "Day of the year", nclass= 100)
# julianday is not strictly a predictor in the model, 
# but there is no certainty that month is a good way
# to describe temporal variation (a calendar month is
# quite an arbitrary from a dolphin's point of view). 
# Plotting against julian day allows to check this further.
# All good so far

# We can also check if there might be more complex patterns not accounted 
# for by the model, for example interactions between the variables.
# Check seasonal variation in diel pattern again ("time by season" interaction):
matplot(tapply(res10.p, list(dat$mon, dat$Time6), mean), type= "l", 
        xlab= "month", ylab= "proportion of hours present", lty= 1)
# still residual variation in diel pattern in later part of the year
# (not surprising as there is nothing in the model aiming at capturing this)

```

\  

10\. Assuming that the model is fine as it is, let's plot the predictions for the probability of presence in relation to time of day `fTime6`. You will need to set the value of other predictors `fTide4`, `fMonth` at a fixed level of your choice, e.g. "1". Optionally, you can add the confidence intervals around the predictions (highly recommended in a report).

* Calculation of confidence intervals:
  + As for the Poisson GLM, you will need to calculate the lower and upper bounds of the 95% CI on the link scale (same method)
  + Only then convert these to the response scale
  + Don't forget that the link function is different though, and so is the function for the back-transformation
  + In R you can do the back-transformation yourself using the equation provided in the lecture, or use the pre-made `plogis` function.

* Suggested approach:
  + create a `data.frame` called `X` containing the data to predict for.
  + use `predict()` with the appropriate options to obtain the fitted values on the link scale and for being able to calculate the confidence intervals later. Store in object `Z`.
  + I suggest you plot the predictions for each level of your categorical predictor as dots using `plot(Z$fit)`. (Some people prefer bars using `barplot(Z$fit)`, but this can make drawing confidence intervals slightly harder)
  + in X, add columns for the fitted values and their confidence intervals, on the response scale (to be calculated).
  + Because in the model the predictions are for categorical predictors, you will need to draw a vertical error bar for each predicted value
  + This can be done using the `arrows` function, with arguments `x0` and `y0`, the X,Y coordinates of the starting point of the arrows, and `x1` and `y1`, the X,Y coordinates of the end point of the arrows. See `?arrows` for further formatting options.
  + Note that for vertical bars like we want, `x0` and `x1` should the same, and `y0` and `y1` are the lower and upper bounds of the confidence intervals that you calculated.

The code is available below for you to unfold, if you don't want to try yourself (you are always welcome to ask demonstrators for help).
\  

```{r Q10b, eval=TRUE, echo=TRUE, results=SOLUTIONS, collapse=TRUE}
PA10.dat4pred<- data.frame(Time6= levels(dat$Time6),
                                fMonth= "10", fTide4= "1")

PA10.pred<- predict(PA10, PA10.dat4pred, type= "link", se.fit= T)

# Convert predictions to the response (probability) scale.
# And add them to the prediction data frame (that bit is optional)
PA10.dat4pred$fit.resp<- exp(PA10.pred$fit)/(1+exp(PA10.pred$fit)) 
# or plogis(PA10.pred$fit)

# lower 95% CI
PA10.dat4pred$LCI<- plogis(PA10.pred$fit - 1.96*PA10.pred$se.fit)
# upper 95% CI
PA10.dat4pred$UCI<- plogis(PA10.pred$fit + 1.96*PA10.pred$se.fit)
```

\  

```{r Q10c, eval=TRUE, echo=TRUE, results=SOLUTIONS, collapse=TRUE, fig.show= ifelse(SOLUTIONS, "asis", "hide"), fig.height=5}
par(mfrow= c(1, 1))
plot(x= 1:6, y= PA10.dat4pred$fit.resp, 
      pch= 16, cex= 1.4, xlab= "Section of day",
		  ylab= "Fitted probability", ylim= c(0, 1),
      main= "Predictions for time of day\n(assuming Tide = 1 and Month = 10)")

arrows(x0= 1:6, x1= 1:6,
          y0= PA10.dat4pred$LCI, y1= PA10.dat4pred$UCI,
          length= 0.02, angle= 90, code= 3)

```

\  

11\. **Optional**: Repeat question 10 for the predictions according to levels of `fTide4`, and then `fMonth`, each time fixing other variables at a value of your choice.

\  

```{r Q11, eval=TRUE, echo=TRUE, results=SOLUTIONS, collapse=TRUE, fig.show= ifelse(SOLUTIONS, "asis", "hide"), fig.height=8, fig.width=8}
par(mfrow= c(2, 2)) # we will need 3 plots

# repeat plotting of predictions for Time6
PA10.dat4pred<- data.frame(Time6= levels(dat$Time6),
                                fMonth= "10", fTide4= "1")

PA10.pred<- predict(PA10, PA10.dat4pred, type= "link", se.fit= T)

PA10.dat4pred$fit.resp<- plogis(PA10.pred$fit) 
# lower 95% CI
PA10.dat4pred$LCI<- plogis(PA10.pred$fit - 1.96*PA10.pred$se.fit)
# upper 95% CI
PA10.dat4pred$UCI<- plogis(PA10.pred$fit + 1.96*PA10.pred$se.fit)

plot(x= 1:6, y= PA10.dat4pred$fit.resp, 
      pch= 16, cex= 1.4, xlab= "Section of day",
		  ylab= "Fitted probability", ylim= c(0, 1),
      main= "Predictions for time of day\n(assuming Tide = 1 and Month = 10)",
      xaxt= "n") # supress automatic x axis (we will draw our own improved axis)

arrows(x0= 1:6, x1= 1:6,
          y0= PA10.dat4pred$LCI, y1= PA10.dat4pred$UCI,
          length= 0.02, angle= 90, code= 3)

axis(side= 1, at= 1:6, label= levels(dat$Time6))

# plotting of predictions for fMonth
PA10.dat4pred<- data.frame(fMonth= levels(dat$fMonth),
                              Time6 = "PM2", fTide4= "1")

PA10.pred<- predict(PA10, PA10.dat4pred, type= "link", se.fit= T)

PA10.dat4pred$fit.resp<- plogis(PA10.pred$fit) 
# lower 95% CI
PA10.dat4pred$LCI<- plogis(PA10.pred$fit - 1.96*PA10.pred$se.fit)
# upper 95% CI
PA10.dat4pred$UCI<- plogis(PA10.pred$fit + 1.96*PA10.pred$se.fit)

plot(x= 1:12, PA10.dat4pred$fit.resp, 
      pch= 16, cex= 1.4, xlab= "Month",
		  ylab= "Fitted probability", ylim= c(0, 1),
      main= "Predictions per month\n(assuming Time = PM2 and Tide = 1)")

arrows(x0= 1:12, x1= 1:12,
          y0= PA10.dat4pred$LCI, y1= PA10.dat4pred$UCI,
          length= 0.02, angle= 90, code= 3)

# plotting of predictions for fTide4
PA10.dat4pred<- data.frame(fTide4= levels(dat$fTide4),
                              Time6 = "PM2", fMonth= "10")

PA10.pred<- predict(PA10, PA10.dat4pred, type= "link", se.fit= T)

PA10.dat4pred$fit.resp<- plogis(PA10.pred$fit) 
# lower 95% CI
PA10.dat4pred$LCI<- plogis(PA10.pred$fit - 1.96*PA10.pred$se.fit)
# upper 95% CI
PA10.dat4pred$UCI<- plogis(PA10.pred$fit + 1.96*PA10.pred$se.fit)

plot(1:4, PA10.dat4pred$fit.resp, 
      pch= 16, cex= 1.4, xlab= "Tidal phase",
		  ylab= "Fitted probability", ylim= c(0, 1),
      main= "Predictions for tide\n(assuming Time = PM2 and Month = 10)",
      xaxt= "n") # supress x axis (we will draw our own)

axis(side= 1, at= 1:4, label= levels(dat$fTide4))

arrows(x0= 1:4, x1= 1:4,
          y0= PA10.dat4pred$LCI, y1= PA10.dat4pred$UCI,
          length= 0.02, angle= 90, code= 3)

```

\  

12\. How satisfied are you with the model, and with all the assumptions being met? What have you learned from it, with respect to the initial aims of the study? Are there areas of improvement?

\  

```{r Q12, eval=SOLUTIONS, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE}
anova(PA10, test= "Chisq")

# at Sutors, dolphins are more likely to be present at night than during the
# day, with a maximum presence from May-July and a second peak in Oct-Nov.
# They have a statistically significant but only very weak preference for 
# certain tidal states in Sutors.

# This model only has additive (main) effects.
# It doesn't ask if there are interactions between our variables.
# For example, the preference for times of day may depend on season,
# or the preference for tidal stages may vary according to time of day or 
# time of the year, depending on how these cycles influence
# the availability of prey.

```

\  

13\. **If you would like to go further**: Re-fit the model with interactions between all categorical predictors, two by two. What hypotheses do these interactions correspond to?

\  

```{r Q13, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE}
PA20<- glm(presence ~ fTide4 * fMonth + fTide4 * Time6 + fMonth * Time6, family= binomial, data= dat)

summary(PA20) # inspect the model coefficients
anova(PA20, test= "Chisq") # gauge significance of predictors
# all terms significant; nothing to drop


```

\  

14\. **If you would like to go further**: Perform model selection "by hand", using the AIC from the model summary, or using `AIC(YourModel)`, and construct an AIC table. There are 18 possible nested models in total, including the full model above. The list of models to evaluate is up to you, from a fully exploratory approach using all 18 models, to a more targeted list of models based on your specific research questions or predictions.

\  

```{r Q14a, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE}
# Because I don't have specific predictions here, and I suspect the presence
# of dolphins at Sutors may respond to all combinations of the 3 environmental
# factors we have, I'll go for a quite systematic exploration here (you may
# have a different logic, knowledge about dolphins, more specific predictions, 
# and a more restricted list of models you consider plausible: that would be
# entirely fine)

# remove interactions one-at-a-time
PA21<- glm(presence ~ fMonth + fTide4 + Time6 + fMonth:fTide4 + fMonth:Time6, family= binomial, data= dat)
PA22<- glm(presence ~ fMonth + fTide4 + Time6 + fMonth:Time6 + fTide4:Time6, family= binomial, data= dat)
PA23<- glm(presence ~ fMonth + fTide4 + Time6 + fMonth:fTide4 + fTide4:Time6, family= binomial, data= dat)
# remove interactions two-at-a-time
PA24<- glm(presence ~ fMonth + fTide4 + Time6 + fMonth:Time6, family= binomial, data= dat)
PA25<- glm(presence ~ fMonth + fTide4 + Time6 + fTide4:Time6, family= binomial, data= dat)
PA26<- glm(presence ~ fMonth + fTide4 + Time6 + fMonth:fTide4, family= binomial, data= dat)
# remove all interactions
PA27<- glm(presence ~ fMonth + fTide4 + Time6, family= binomial, data= dat)

AIC(PA20)
AIC(PA21)
AIC(PA22)
AIC(PA23)
AIC(PA24)
AIC(PA25)
AIC(PA26)
AIC(PA27)

# PA24 seems best so far

# remove the main effect not involved in the interaction of PA24 (fTide4)
PA28<- glm(presence ~ fMonth + Time6 + fMonth:Time6, family= binomial, data= dat)
AIC(PA28)

# we could simplify further, but it is unlikely that simpler models 
# would be supported based on what we know, so I'll stop here

# Constructing a table 
# (you can do this with pen and paper, or in R for example like this)
ModelStructure<- c(
  "fTide4 * fMonth + fTide4 * Time6 + fMonth * Time6",     
  "fMonth + fTide4 + Time6 + fMonth:fTide4 + fMonth:Time6",
  "fMonth + fTide4 + Time6 + fMonth:Time6 + fTide4:Time6" ,
  "fMonth + fTide4 + Time6 + fMonth:fTide4 + fTide4:Time6",
  "fMonth + fTide4 + Time6 + fMonth:Time6",
  "fMonth + fTide4 + Time6 + fTide4:Time6",
  "fMonth + fTide4 + Time6 + fMonth:fTide4",
  "fMonth + fTide4 + Time6",
  "fMonth + Time6 + fMonth:Time6")

AICval<- c(AIC(PA20),
            AIC(PA21),
            AIC(PA22),
            AIC(PA23),
            AIC(PA24),
            AIC(PA25),
            AIC(PA26),
            AIC(PA27),
            AIC(PA28))

ModelName<- c("PA20",
            "PA21",
            "PA22",
            "PA23",
            "PA24",
            "PA25",
            "PA26",
            "PA27",
            "PA28")

# combine models and AIC values in a table
ModSelTab<- data.frame(model= ModelName, structure= ModelStructure, AIC= AICval)

# sort the table by increasing AIC value
ModSelTab<- ModSelTab[order(ModSelTab$AIC), ]

# compute AIC differences with best model, and round to 2 decimals
ModSelTab$delta<- round(ModSelTab$AIC - ModSelTab$AIC[1], 2)

# compute AIC weight, and round to 2 decimals
ModSelTab$weight<- round(exp(-ModSelTab$delta / 2) / sum(exp(-ModSelTab$delta / 2)), 2)
```

```{r Q14b, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE}
require(knitr)
kable(ModSelTab)

# Model PA24 is far ahead, and attracts almost all the AIC weight, accordingly.

# Depending on the set of models you decided to compare, 
# your best model and AIC weights may vary from mine.

```

\  

15\. **If you would like to go further**: Perform model validation

\  

```{r Q15, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE, fig.show= ifelse(SOLUTIONS, "asis", "hide"), fig.height=8, fig.width=8}
res24.p<- resid(PA24, type= "pearson")

library(arm)
par(mfrow= c(2, 2))
binnedplot(x= dat$tideangle_deg, y=  res24.p, xlab= "Tide angle", nclass= 100)
# okay
binnedplot(x= dat$mh, y=  res24.p, xlab= "hour")
# okay
binnedplot(x= dat$julianday, y=  res24.p, xlab= "Day of the year", nclass= 100)
# okay
# Check seasonal variation in diel pattern again ("time by season" interaction):
matplot(tapply(res24.p, list(dat$mon, dat$Time6), mean), type= "l", 
        xlab= "month", ylab= "proportion of hours present", lty= 1)
# Residual variation is tiny (check y-axis and compare with Question 9); 
# no consistent pattern of variation. Pretty good!

# There are few assumptions for the Bernoulli distribution other than 
# observations being zeros and ones.
# Some assumptions valid for all models still apply here, such as: model 
# correctly specified; independent
# residuals. The latter is violated in this data set, due to consecutive 
# measurements in time. This issue
# is explored in the linked paper, using mixed models for non-independent data 
# (covered in the course BI5302). 
# The paper also uses GAMs for avoiding the discretization of 
# continuous variables, and
# accounting for the cyclicity of the preditors (estimates at each end should 
# match, e.g. 31st Dec-1st Jan, or 23:59 - 00:00)

```

\  

16\. **If you would like to go even further**: Interpret the model biologically. 

\  

```{r Q16, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE, fig.show= ifelse(SOLUTIONS, "asis", "hide"), fig.height=8, , fig.width=8}

# Model PA24 assumes that dolphin presence (actually, probability of recording) 
# changes according to time of year, time of day and tidal stage, and that the
# effect of time of day changes with the time of year (fMonth:Time6).

summary(PA24)
# This is tricky to interpret due to the number of coefficients (75), 
# and the presence of interactions. Best to use plots!

# Let's illustrate the differences in predictions for two different months, 
# for example June and December (this could be done for each of the 12 months)

par(mfrow= c(1, 2))
# June
dat4pred<- expand.grid(Time6= levels(dat$Time6),
                fMonth= "6",
								fTide4= "1")
PA24.pred<- predict(PA24, dat4pred, type= "link", se.fit= T)
dat4pred$fit.resp<- plogis(PA24.pred$fit)
dat4pred$LCI<- plogis(PA24.pred$fit - 1.96*PA24.pred$se.fit)
dat4pred$UCI<- plogis(PA24.pred$fit + 1.96*PA24.pred$se.fit)
plot(as.numeric(dat4pred$Time6), dat4pred$fit.resp, pch= 16, 
	  cex= 1.4, main= paste("Month =", 6),
    col= 1, xlab= "Section of day",
	  ylab= "Fitted probability (assuming Tide = 1)", ylim= c(0, 1))
arrows(x0= as.numeric(dat4pred$Time6), x1= as.numeric(dat4pred$Time6),
    y0= dat4pred$LCI, y1= dat4pred$UCI,
	  col= grey(0.5), length= 0.02, angle= 90, code= 3)

# December
dat4pred<- expand.grid(Time6= levels(dat$Time6),
                fMonth= "12",
								fTide4= "1")
PA24.pred<- predict(PA24, dat4pred, type= "link", se.fit= T)
dat4pred$fit.resp<- plogis(PA24.pred$fit)
dat4pred$LCI<- plogis(PA24.pred$fit - 1.96*PA24.pred$se.fit)
dat4pred$UCI<- plogis(PA24.pred$fit + 1.96*PA24.pred$se.fit)
plot(as.numeric(dat4pred$Time6), dat4pred$fit.resp, pch= 16, 
	  cex= 1.4, main= paste("Month =", 12),
    col= 1, xlab= "Section of day",
	  ylab= "Fitted probability (assuming Tide = 1)", ylim= c(0, 1))
arrows(x0= as.numeric(dat4pred$Time6), x1= as.numeric(dat4pred$Time6),
    y0= dat4pred$LCI, y1= dat4pred$UCI,
	  col= grey(0.5), length= 0.02, angle= 90, code= 3)

# In June, dolphins seem to have a similar probability of being recorded
# at any time of the day and night, whereas in December they are mostly
# using the site by night (ca. 40% chances of being present against 
# only ca. 10% in the middle of the day)

# (FOR THE R GEEKS OUT THERE)
# For plots of predictions for all 12 months, it is possible to automate
# the process using a loop:
par(mfrow= c(3, 4))
for(month in 1:12){ 
  # at the first iteration, the variable `month` will take value 1, then
  # at the second iteration, the variable `month` will take value 2, 
  # etc... until iteraction 12
	dat4pred<- expand.grid(Time6= levels(dat$Time6),
                                fMonth= as.character(month),
								fTide4= "1")
	PA24.pred<- predict(PA24, dat4pred, type= "link", se.fit= T)
	dat4pred$fit.resp<- plogis(PA24.pred$fit)
	dat4pred$LCI<- plogis(PA24.pred$fit - 1.96*PA24.pred$se.fit)
	dat4pred$UCI<- plogis(PA24.pred$fit + 1.96*PA24.pred$se.fit)
	plot(as.numeric(dat4pred$Time6), dat4pred$fit.resp, pch= 16, 
		  cex= 1.4, main= paste("Month =", month),
          col= 1, xlab= "Section of day",
		  ylab= "Fitted probability (assuming Tide = 1)", ylim= c(0, 1))
	arrows(x0= as.numeric(dat4pred$Time6), x1= as.numeric(dat4pred$Time6),
          y0= dat4pred$LCI, y1= dat4pred$UCI,
		  col= grey(0.5), length= 0.02, angle= 90, code= 3)
} # end of one iteration, start of the next

# According to the better supported model, they tend to use the site
# more in May, June and 
# July day and night, visit mostly by night from October to December,
# and seldom from Jan to March.

# Of note is the low proportion of deviance explained by the model,
# despite its complexity (75 parameters):
(PA24$null.deviance - PA24$deviance) /
	PA24$null.deviance 
# 10%. This is quite normal with Bernoulli data.

```

\  

End of the Binomial (Bernoulli) GLM - dolphin behavioural plasticity exercise


\  

**For info,** background on the data and the study can be found in this [short video](https://abdn.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=619e9ee8-241a-4924-8550-ac5401283e2a), courtesy of Paul Thompson. The exercise can be done entirely without consulting this. I recommend you watch this or any companion material (the referenced paper) outside the synchronous session, to make the most of the time you have with demonstrators to progress on the exercises. 

\  

**For info,** the publication here offers a different approach to analysing these data, using slightly fancier GLMs with smooth terms (called GAMs, for Generalized Additive Models), and a few additional refinements: [https://www.nature.com/articles/s41598-019-38900-4]. What assumptions differ between this and your approach?

\  

**For info,** the full original data (10 Mb) are publicly available here: [https://datadryad.org/stash/dataset/doi:10.5061/dryad.k378542], in case of interest.

